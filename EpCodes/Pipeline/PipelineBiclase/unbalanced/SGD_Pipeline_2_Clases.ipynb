{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bkbSHynI8H9c"
      },
      "outputs": [],
      "source": [
        "# libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import BaseEstimator\n",
        "import time\n",
        "\n",
        "#Visualizers\n",
        "from yellowbrick.classifier import ClassificationReport\n",
        "from yellowbrick.classifier import ClassPredictionError\n",
        "from yellowbrick.classifier import ConfusionMatrix\n",
        "from yellowbrick.classifier import ROCAUC\n",
        "from yellowbrick.classifier import PrecisionRecallCurve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import hamming_loss\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import zero_one_loss\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "#Classifiers\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#Neural Network\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sbU3yOGj8KzP"
      },
      "outputs": [],
      "source": [
        "data_path6 = 'Epileptic Seizure Recognition.csv'\n",
        "figures_path = './figures'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fCkkhC_j8M4e"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(figures_path):\n",
        "    os.makedirs(figures_path)\n",
        "if not os.path.exists(figures_path+\"/6FP\"):\n",
        "    os.makedirs(figures_path+\"/6FP\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b-8NL4NQDuAA"
      },
      "outputs": [],
      "source": [
        "Data = pd.read_csv(data_path6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VK4vySMODya5"
      },
      "outputs": [],
      "source": [
        "Data=Data.drop([\"Unnamed\"],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZDBy0x6D0yw",
        "outputId": "c940a211-2205-4683-9ad7-d0af6a9e7978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (11500, 178)\n",
            "Labels shape: (11500,)\n"
          ]
        }
      ],
      "source": [
        "Labels = Data['y'].values\n",
        "Features = Data.drop(['y'],axis=1).values\n",
        "\n",
        "\n",
        "print('Features shape:', Features.shape)\n",
        "print('Labels shape:', Labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DCbVYJVaREml"
      },
      "outputs": [],
      "source": [
        "for i in range(len(Labels)):\n",
        "  if Labels[i]==2 or Labels[i]==3 or Labels[i]==4 or Labels[i]==5:\n",
        "    Labels[i]=0\n",
        "  else:\n",
        "    Labels[i]=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjK4dAj56TEq",
        "outputId": "5e0dc159-d59a-4eea-df80-b807d85f0e10"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I1XCFoG38QHG"
      },
      "outputs": [],
      "source": [
        "#Write function for class-centric metrics\n",
        "# Classification report\n",
        "def CR_viz():\n",
        "    def Class_report(model,classes):\n",
        "        visualizer = ClassificationReport(model, classes=classes, support=True)\n",
        "        train_start_time = time.time()\n",
        "        visualizer.fit(X_train, y_train)  # Fit the visualizer and the model\n",
        "        print(f'Train runtime: {time.time()-train_start_time}')\n",
        "        test_start_time = time.time()\n",
        "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
        "        print(f'Test runtime: {time.time()-test_start_time}')\n",
        "        return visualizer.poof()\n",
        "    for name, classifier in zip(names, classifiers):\n",
        "        fig, ax = plt.subplots(nrows=1, ncols=1 )\n",
        "        Class_report(classifier,classes)\n",
        "        fig.savefig(figures_path+\"/\"+str(len(classes))+\"FP/\"+name+\"_CR.pdf\")\n",
        "\n",
        "#Class Prediction Error\n",
        "def CPE_viz():\n",
        "    def CPE(model,classes):\n",
        "        visualizer = ClassPredictionError(model, classes=classes)\n",
        "        visualizer.fit(X_train, y_train)  # Fit the visualizer and the model\n",
        "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
        "        return visualizer.poof()\n",
        "    for name, classifier in zip(names, classifiers):\n",
        "        fig, ax = plt.subplots(nrows=1, ncols=1 )\n",
        "        CPE(classifier,classes)\n",
        "        fig.savefig(figures_path+\"/\"+str(len(classes))+\"FP/\"+name+\"_CPE.pdf\")\n",
        "\n",
        "#Confusion matrix\n",
        "def CM_viz():\n",
        "    def CM(model,classes):\n",
        "        visualizer = ConfusionMatrix(model, classes=classes, percent=True)\n",
        "        visualizer.fit(X_train, y_train)  # Fit the visualizer and the model\n",
        "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
        "        return visualizer.poof()\n",
        "    for name, classifier in zip(names, classifiers):\n",
        "        fig, ax = plt.subplots(nrows=1, ncols=1 )\n",
        "        CM(classifier,classes)\n",
        "        fig.savefig(figures_path+\"/\"+str(len(classes))+\"FP/\"+name+\"_CM.pdf\")\n",
        "\n",
        "#ROC-AUC\n",
        "def ROC_viz():\n",
        "    def ROC(model,classes):\n",
        "        visualizer = ROCAUC(model, classes=classes)\n",
        "        visualizer.fit(X_train, y_train)  # Fit the visualizer and the model\n",
        "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
        "        return visualizer.poof()\n",
        "    for name, classifier in zip(names, classifiers):\n",
        "        fig, ax = plt.subplots(nrows=1, ncols=1 )\n",
        "        ROC(classifier,classes)\n",
        "        fig.savefig(figures_path+\"/\"+str(len(classes))+\"FP/\"+name+\"_ROC.pdf\")\n",
        "\n",
        "#Precision Recall Curve\n",
        "def PRC_viz():\n",
        "    def PRC(model,classes):\n",
        "        visualizer = PrecisionRecallCurve(model,classes=classes, per_class=True, iso_f1_curves=False,\n",
        "    fill_area=False, micro=False)\n",
        "        visualizer.fit(X_train, y_train)  # Fit the visualizer and the model\n",
        "        visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
        "        return visualizer.poof()\n",
        "    for name, classifier in zip(names, classifiers):\n",
        "        fig, ax = plt.subplots(nrows=1, ncols=1 )\n",
        "        PRC(classifier,classes)\n",
        "        fig.savefig(figures_path+\"/\"+str(len(classes))+\"FP/\"+name+\"_PRC.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w5eM7ZC28Sym"
      },
      "outputs": [],
      "source": [
        "# Write function for aggregate metrics\n",
        "def classifier_metrics():\n",
        "    def metrics(model):\n",
        "        #     model=model_name()\n",
        "        model.fit(X_train, y_train)  # Fit the visualizer and the model\n",
        "        y_pred = model.predict(X_test)\n",
        "        try:\n",
        "            y_prob = model.predict_proba(X_test)\n",
        "            log_metric = log_loss(y_test,y_prob)\n",
        "        except:\n",
        "            y_prob = \"Not probablistic\"\n",
        "            log_metric = 0\n",
        "        else:\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "        acc_score=accuracy_score(y_test,y_pred)\n",
        "        c_k_s=cohen_kappa_score(y_test,y_pred)\n",
        "        zero_met=zero_one_loss(y_test,y_pred)\n",
        "        hl=hamming_loss(y_test,y_pred)\n",
        "        mc=matthews_corrcoef(y_test,y_pred)\n",
        "        print('accuracy_score: {0:.4f}'.format(acc_score))\n",
        "        print('cohen_kappa_score: {0:.4f}'.format(c_k_s))\n",
        "        print('log_loss: {0:.4f}'.format(log_metric))\n",
        "        print('zero_one_loss: {0:.4f}'.format(zero_met))\n",
        "        print('hemming_loss: {0:.4f}'.format(hl))\n",
        "        print('matthews_corrcoef: {0:.4f}'.format(mc))\n",
        "    for name in classifiers:\n",
        "        print (str(name))\n",
        "        metrics(name)\n",
        "        print()\n",
        "        print (\"---------------------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KuoDu1HJ8WIv"
      },
      "outputs": [],
      "source": [
        "class KerasBatchClassifier(KerasClassifier, BaseEstimator):\n",
        "    def __init__(self, model, **kwargs):\n",
        "        super().__init__(model)\n",
        "        self.fit_kwargs = kwargs\n",
        "        self._estimator_type = 'classifier'\n",
        "\n",
        "    def fit(self, x, y, *args, **kwargs):\n",
        "        y = np.array(y)\n",
        "        if len(y.shape) == 2 and y.shape[1] > 1:\n",
        "          self.classes_ = np.arange(y.shape[1])\n",
        "        elif (len(y.shape) == 2 and y.shape[1] == 1) or len(y.shape) == 1:\n",
        "          self.classes_ = np.unique(y)\n",
        "          y = np.searchsorted(self.classes_, y)\n",
        "        else:\n",
        "          raise ValueError('Invalid shape for y: ' + str(y.shape))\n",
        "        self.n_classes_ = len(self.classes_)\n",
        "        return super(KerasClassifier, self).fit(x, y, **self.fit_kwargs)\n",
        "\n",
        "def FullyConnected():\n",
        "  inputs = Input(shape=(X_train.shape[1],), name=\"input_1\")\n",
        "  layers = Dense(512, activation=\"selu\")(inputs)\n",
        "  layers = Dense(256, activation=\"selu\")(layers)\n",
        "  layers = Dense(128, activation=\"selu\")(layers)\n",
        "  layers = Dense(64, activation=\"selu\")(layers)\n",
        "  predictions = Dense(len(classes), activation=\"softmax\", name=\"output_1\")(layers)\n",
        "  model = Model(inputs = inputs, outputs=predictions)\n",
        "  optimizer=RMSprop()\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf33Yytd8gkH",
        "outputId": "6d99b787-392b-47e8-a81d-5adeab2559a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data shape: (9200, 178)\n",
            "Train labels shape: (9200,)\n",
            "Test data shape: (2300, 178)\n",
            "Test labels shape: (2300,)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Features, Labels, test_size=0.2, stratify=Labels, random_state=42)\n",
        "\n",
        "print('Train data shape:', X_train.shape)\n",
        "print('Train labels shape:', y_train.shape)\n",
        "print('Test data shape:', X_test.shape)\n",
        "print('Test labels shape:', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jb-NXtN1ENaJ"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler().fit(X_train)\n",
        "\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "knSdlA-7EP9_"
      },
      "outputs": [],
      "source": [
        "#classes\n",
        "classes = [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "J1LNxWmoETbv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "57cb1eb5-a32f-4b7f-f1b7-5ce684e27388"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=Pipeline(steps=[('clf', SGDClassifier())]),\n",
              "             param_grid={'clf__alpha': [0.0001, 0.001, 0.01],\n",
              "                         'clf__loss': ['hinge', 'log', 'modified_huber'],\n",
              "                         'clf__max_iter': [1000, 2000, 3000],\n",
              "                         'clf__penalty': ['l2', 'l1', 'elasticnet']})"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;clf&#x27;, SGDClassifier())]),\n",
              "             param_grid={&#x27;clf__alpha&#x27;: [0.0001, 0.001, 0.01],\n",
              "                         &#x27;clf__loss&#x27;: [&#x27;hinge&#x27;, &#x27;log&#x27;, &#x27;modified_huber&#x27;],\n",
              "                         &#x27;clf__max_iter&#x27;: [1000, 2000, 3000],\n",
              "                         &#x27;clf__penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Pipeline(steps=[(&#x27;clf&#x27;, SGDClassifier())]),\n",
              "             param_grid={&#x27;clf__alpha&#x27;: [0.0001, 0.001, 0.01],\n",
              "                         &#x27;clf__loss&#x27;: [&#x27;hinge&#x27;, &#x27;log&#x27;, &#x27;modified_huber&#x27;],\n",
              "                         &#x27;clf__max_iter&#x27;: [1000, 2000, 3000],\n",
              "                         &#x27;clf__penalty&#x27;: [&#x27;l2&#x27;, &#x27;l1&#x27;, &#x27;elasticnet&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;clf&#x27;, SGDClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "pipeline = Pipeline([    ('clf', SGDClassifier())])\n",
        "\n",
        "parameters = {\n",
        "    'clf__loss': ['hinge', 'log', 'modified_huber'],\n",
        "    'clf__penalty': ['l2', 'l1', 'elasticnet'],\n",
        "    'clf__alpha': [0.0001, 0.001, 0.01],\n",
        "    'clf__max_iter': [1000, 2000, 3000],\n",
        "}\n",
        "grid_search = GridSearchCV(pipeline, parameters, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ylwGLrOFVwn",
        "outputId": "c46aeed8-6b8e-4e58-9504-040646dc52f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores parámetros encontrados:\n",
            "{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 2000, 'clf__penalty': 'l2'}\n",
            "Puntuación de validación cruzada media del mejor modelo:\n",
            "0.8482608695652173\n"
          ]
        }
      ],
      "source": [
        "print(\"Mejores parámetros encontrados:\")\n",
        "print(grid_search.best_params_)\n",
        "print(\"Puntuación de validación cruzada media del mejor modelo:\")\n",
        "print(grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekiz-fPL5TKx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}